{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "인공지능 사관학교 1주차 과제 :: 인공지능 .ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLebpeySsIqstrMO2H0li3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/songsunn/precourse.gj-aischool/blob/master/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EC%82%AC%EA%B4%80%ED%95%99%EA%B5%90_1%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "not9xMgI9bx-",
        "colab_type": "text"
      },
      "source": [
        "# 인공지능 사관학교 프리코스 목차\n",
        "***\n",
        "##1. 서론\n",
        "\n",
        "##2. 분야별 AI 활용 및 서비스\n",
        "\n",
        "##- 2-1. 언어 분야에서의 인공지능\n",
        "\n",
        "- 2-1.1 언어 AI 해외 대표 서비스: 구글 '버트'\n",
        "- 2-1.2 구글 '버트'의 음성 AI 기술 구현 : 자연어 처리\n",
        "- 2-1.3 언어 AI 기술의 확장: 자연어 대화 인터페이스 \n",
        "\n",
        "##- 2-2. 음성 분야에서의 인공지능\n",
        "\n",
        "######  - 2-2.1  음성 AI의 기반 기술: 딥러닝과 자연어 처리\n",
        "######  - 2-2.2  음성 AI의 해외 대표 서비스: 아마존 '알렉사'\n",
        "######  - 2-2.3  음성 AI의 국내 대표 서비스: SKT '누구'\n",
        "######  - 2-2.4  음성 AI의 기술 구현: 자연어 처리\n",
        "######  - 2-2.5  음성 AI의 기술 전망: 자연어 처리\n",
        "\n",
        "##- 2-3. 이미지 분야에서의 인공지능\n",
        "\n",
        "######  - 2-3.1  인공지능으로 분류하는 이미지: 구글 포토 서비스\n",
        "######  - 2-3.2  이미지 딥러닝 기술 : 데이터 기반 이미지 분류\n",
        "######  - 2-3.3  구글포토의 이미지 딥러닝 기술 구현\n",
        "\n",
        "##- 2-4  자율주행 분야에서의 인공지능\n",
        "\n",
        "######  - 2-4.1  자율주행 개념\n",
        "######  - 2-4.2  자율주행차 주요 기술: 인공지능의 대표적인 이론, 딥러닝\n",
        "######  - 2-4.3  자율주행차 인공지능 기술 구현 : 딥러닝\n",
        "######  - 2-4.4  자율주행 대표 서비스: 앱티브의 라이드쉐어링\n",
        "\n",
        "##3. 결론\n",
        "##4. 참고문헌\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1rbb6WK5TK-",
        "colab_type": "text"
      },
      "source": [
        "# 1. 서론\n",
        "\n",
        "지난 2012년 딥러닝의 등장과 함께 본격적인 개화기를 맞은 인공지능(AI)이 자연어를 중심으로 새로운 전기를 맞을 전망이라는 기사를 본 적이 있다. AI의 언어 독해 능력과 문맥 이해, 목소리 변조 등의 기술이 급속도로 발전하면서 학계에서는 여태까지 보지 못했던 종류의 대화형 AI의 등장을 기대된다. 국문학과를 전공으로 하였기 때문에 인공지능을 통해 언어의 장벽을 넘을 수 있다는 기회의 장에 참여하고 싶어 인공지능 공부를 시작하게 되었다. 언어, 음성, 이미지 그리고 자율주행 외에도 다양한 분야에서 인공지능이 적용되고, 연구되고 있다. 이번 글에서 위의 4가지 분야에서 인공지능의 어떤 기술이 사용되고, 구현되는지 그리고 어떤 서비스가 만들어졌는지 알아보고자 한다. \n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47tf3AbfCWI9",
        "colab_type": "text"
      },
      "source": [
        "# 2. 분야별 AI 활용 및 서비스"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eLg2IkqCQF3",
        "colab_type": "text"
      },
      "source": [
        "# 2-1. 언어 분야에서의 인공지능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhD8RNLlCI0d",
        "colab_type": "text"
      },
      "source": [
        "## 2-1.1 음성 AI 해외 대표 서비스: 구글 '버트'\n",
        "\n",
        "구글이 공개한 인공지능(AI) 언어모델 ‘BERT(이하 버트)는 일부 성능 평가에서 인간보다 더 높은 정확도를 보이며 2018년 말 현재, 자연 언어 처리 AI의 최첨단 딥러닝 모델이다. \n",
        "\n",
        "또한 BERT는 언어표현 사전학습의 새로운 방법으로 그 의미는 '큰 텍스트 코퍼스'를 이용하여 범용목적의 '언어 이해'' 모델을 훈련시키는 것과 그 모델에 관심 있는 실제의 자연 언어 처리 태스크에 적용하는 것이다.\n",
        "\n",
        "특히 BERT는 종래보다 우수한 성능을 발휘한다. BERT는 자연언어 처리 태스크를 교육 없이 양방향으로 사전학습하는 첫 시스템이기 때문이다. 교육 없음이란 BERT가 보통의 텍스트 코퍼스만을 이용해 훈련되고 있다는 것을 의미한다. 이것은 웹 상에서 막대한 양의 보통 텍스트 데이터가 여러 언어로 이용 가능하기 때문에 중요한 특징으로 꼽는다.\n",
        "\n",
        "사전학습을 마친 특징 표현은 문맥에 '의존하는 방법'와 '의존하지 않는 방법'의 어느 방법도 있을 수 있다. 또 문맥에 의존하는 특징적인 표현은 단방향인 경우와 혹은 양방향일 경우가 있다. word2vec나 GloVe와 같이 문맥에 의존하지 않는 모델에서는, 어휘에 포함되는 각 단어마다 '단어 삽입'이라는 특징 표현을 생성한다. 따라서, 'bank'라는 단어는 'bank deposit' 또는 'river bank'과 같은 특징으로 표현되며, 문맥에 의존하는 모델에서는 문장에 포함되는 다른 단어를 바탕으로 각 단어의 특징을 표현 생성한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIUtYScICpFM",
        "colab_type": "text"
      },
      "source": [
        "## 2-1.2 구글 '버트'의 음성 AI 기술 구현 : 자연어 처리\n",
        "\n",
        "BERT는 문맥에 의존하는 특징적인 표현의 전학습을 실시하는 대응을 바탕으로 구축되었다. 그러한 대응은 Semi-supervised Sequence Learning, Generative Pre-Training, ELMo, 및 ULMFit를 포함하며, 대응에 의한 모델은 모두 단방향 혹은 얕은 양방향이다. 각 단어는 단지 그 왼쪽(혹은 오른쪽)에 존재하는 단어에 의해서만 문맥의 고려가 되는 것을 의미한다.\n",
        "\n",
        "예를 들어, I made a bank deposit라는 문장은 bank의 단방향 특징표현은 단지 I made a만에 의해 결정되며, deposit은 고려되지 않는다. 몇개의 이전의 대응에서는 분리한 좌문맥모델과 우문맥모델에 의한 특징표현을 조합하고 있었지만, 이것은 얕은 양방향 방법이다. BERT는 bank를 왼쪽과 오른쪽 양쪽의 문맥 I made a ... deposit을 딥 뉴럴 네트워크(Deposit)의 최하층에서 이용해 특징을 표현하기 때문에 BERT는 '딥 양방향(deeply bidirectional)'이다.\n",
        "\n",
        "BERT는 간단한 접근법을 사용한다. 입력에서 단어의 15%를 숨기고 딥 양방향 Transformer encoder(관련 논문다운)를 통해 전체 시퀀스를 실행한 다음 마스크 된 단어만 예측한다. 예를 들어, 아래와 같이 문간의 관계를 학습하기 위해서는 임의의 단언어 코퍼스에서 생성 가능한 심플한 작업을 이용하여 학습한다. A와 B의 두 개의 글을 받았을 때 B가 A의 뒤에 오는 실제 문장인지, 코퍼스 안의 랜덤한 글인지를 판정하는 태스크이다.\n",
        "\n",
        "큰 모델을 큰 코퍼스로 긴 시간을 들여(100만 갱신 스텝) 훈련했다. 그것이 BERT이며, 이용은 '사전학습'과 '전이학습'의 2단계로 구분된다.\n",
        "\n",
        "사전학습은 상당히 고가로 4에서 16개의 Cloud TPU로 4일(12 층의 Transformer 모델의 경우 4개의 TPU를 사용하여 4일, 24층 Transformer 모델의 경우 16개의 TPU를 사용하여 4일이라는 의미) 각 언어마다 1회만의 순서이다. 자연 언어 처리 개발자는 처음부터 자신의 모델을 사전 학습할 필요가 없다.\n",
        "\n",
        "전이학습은 저렴하며,사전학습이 끝난 모델을 사용하여 하나의 Cloud TPU를 이용, 1시간 GPU를 사용하면 2, 3시간만에 재현할 수 있다. 예를 들면 SQuAD는 하나의 Cloud TPU를 이용 30분으로 하나의 시스템으로서는 최첨단인 91.0%의 Dev F1을 달성할 수 있다.이밖에 BERT의 또 다른 중요한 측면은 많은 종류의 자연 언어 처치 태스크로 인해 매우 쉽게 채택될 수 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YyhknZLD7Qo",
        "colab_type": "text"
      },
      "source": [
        "## 2-1.3 언어 AI 기술의 확장: 자연어 대화 인터페이스 \n",
        "\n",
        "이처럼 자연어 처리 기술에 대한 연구가 발달하면서 이 기술이 가장 적용되는 분야에 대한 관심도 뜨겁다. 바로 구글사의 어시스턴트, 아마존사의 에코, 삼성전자의 빅스비 등으로 대표되는 자연어 대화 인터페이스 분야이다. 자연어 대화 인터페이스는 초기에는 개인의 디바이스나 서비스 기능 활용, 관심사 검색, 채팅 등을 지원하는 개인 비서봇이 주류를 이뤘으나, 현재는 금융이나 쇼핑 등의 도메인에서 상품에 대한 설명이나 구매, 예약 등을 지원하는 상담봇의 형태로 상용화되고 있다. 이는 스마트 디바이스를 위한 개인 비서 서비스는 주로 스마트폰과, 스마트 워치 등에서서 활용되고 있는데 이는 다음 챕터인 음성 AI 분야에서 보다 자세히 알아보도록 하겠다. \n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUyK-XCi3oTj",
        "colab_type": "text"
      },
      "source": [
        "# 2-2 . 음성 분야에서의 인공지능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ttsj2Dk3v_G",
        "colab_type": "text"
      },
      "source": [
        "##2-2.1  음성 AI의 기반 기술: 딥러닝과 자연어 처리\n",
        "\n",
        "음성 AI 시스템과 플랫폼은 여러 기술 요소에 기반해 구현된다. 이 중 가장\n",
        "기본적인 것은 사람의 음성을 텍스트 데이터 형태로 바꿔주는 음성\n",
        "인식(Speech Recognition) 기술이다. 음성 입력 과정에서 음성 인식 정확도를\n",
        "높이기 위해 녹음 장치로 수집한 데이터에서 잡음과 불필요한 데이터를\n",
        "걸러주는 전처리 기술도 함께 활용된다. 음성 인식 기술은 음성 신호로부터\n",
        "문자 정보를 출력하는데, 상용 서비스에 적용되는 음향 정보 해독은 확률 통계\n",
        "방식을 사용한다. 여기에 2010년대 이후 등장한 딥러닝 기술이 적용되면서\n",
        "음성 인식의 정확도가 비약적으로 향상되었다. 딥러닝은 데이터가 많아질수록\n",
        "성능과 정확도가 높아지기 때문에 음성 인식 기능 향상을 위해서는 방대한\n",
        "언어 자료를 수집하고 분석하는 데이터 분석 기술이 필수적이다.\n",
        "음성을 일단 텍스트 데이터로 올바르게 변환한 이후에는, 텍스트를 컴퓨터가\n",
        "이해할 수 있 는 형태로 변환하는 자연어 처 리 (Natural Language\n",
        "Understanding) 과정을 거쳐야 한다. 자연어 처리는 어절을 최소의 의미\n",
        "단위인 ‘형태소’로 추출하거나 실제 언어 샘플 데이터인 말뭉치를 활용해\n",
        "구절과 구문을 분석함으로써 이루어진다. 자연어 처리 또한 머신러닝, 딥러닝\n",
        "기술을 주로 활용한다. 시맨틱 분석은 데이터의 의미를 해석하고 검색하는\n",
        "기술로, 기존에 축적된 지식(Knowledge) 데이터베이스에서 유용한 정보를\n",
        "검색∙선별함으로써 결과값을 생성한다. 결과값은 질문에 대한 답변, 요청한\n",
        "정보나 기능으로 나타날 수 있고, 결과값이 언어적 형태일 경우에는 음성으로\n",
        "출력되며, 기능일 경우에는 해당 서비스나 조작을 실행하게 된다.\n",
        "음성 AI 기술에 공통적으로 사용되는 기반 기술에는 인공 지능의 한 분야인\n",
        "딥러닝, 방대한 데이터를 수집하고 분석하는 빅데이터, 서버로 데이터를\n",
        "전송해 처리하는 클라우드 기술이 포함된다. 최근 딥러닝 기술의 고도화,\n",
        "스마트 스피커 등 각종 단말에서 수집되는 방대한 데이터, 클라우드 인프라의\n",
        "발달이 음성 AI 기술의 진화에 핵심적인 역할을 수행하고 있다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OG0KurE37ix",
        "colab_type": "text"
      },
      "source": [
        "##2-2.2  음성 AI의 해외 대표 서비스: 아마존 '알렉사'\n",
        "\n",
        "아마존 알렉사는 세계 최대의 전자상거래 기업인 아마존이 2014년 11월\n",
        "출시한 스마트 스피커 에코(Echo)에 탑재된 음성 인식 AI 플랫폼이다.\n",
        "알렉사는 사용자의 음성을 클라우드에서 분석해 명령을 수행하는 방식으로\n",
        "작동한다. 아마존은 2015년 6월 다른 업체의 서비스를 손쉽게 알렉사의\n",
        "기능으로 추가할 수 있는 개방형 API인 ‘알렉사 스킬(Alexa Skills)’을 발표했다.\n",
        "아마존 이외의 외부 업체들은 알렉사 스킬을 활용해 알렉사가 탑재된\n",
        "기기에서 새로운 서비스를 쉽게 만들 수 있다. 예를 들어 도미노에서는\n",
        "음성으로 도미노 피자를 주문할 수 있는 스킬을 개발했으며, 우버에서는 택시\n",
        "호출이 가능한 스킬을 선보였다. 스마트폰에 설치하는 모바일 앱과 같은\n",
        "역할을 스마트 스피커에서 스킬이 수행하고 있는 것이다. 음악, 교육, 쇼핑,\n",
        "키즈 등 다양한 카테고리에서 방대한 수의 스킬이 개발되면서 알렉사 스킬은\n",
        "2019년 9월 기준으로 10만 개를 넘어섰다. 한편 아마존은 알렉사 플랫폼을\n",
        "확장하기 위한 노력에 집중하고 있다. 알렉사 보이스 서비스(AVS, Alexa Voice\n",
        "Service)를 다른 기업의 하드웨어에 탑재할 경우, 알렉사의 음성 인식 기능을\n",
        "해당 기기에서 사용할 수 있다. 현재 삼성전자, LG전자의 스마트TV뿐만\n",
        "아니라 중국 기업들의 다양한 스마트TV, 서드파티 업체의 스마트 스피커, GM,\n",
        "람보르기니의 자동차 인포테인먼트 시스템 등이 알렉사 플랫폼을 채택하고\n",
        "있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM-TXEvz4JP2",
        "colab_type": "text"
      },
      "source": [
        "## 2-2.3  음성 AI의 국내 대표 서비스: SKT '누구\n",
        "\n",
        "통신기업인 SK텔레콤은 2016년 9월 스마트 스피커인 누구(NUGU)를\n",
        "출시했으며, 이 제품에는 SK텔레콤이 자체적으로 개발한 음성 인식 AI\n",
        "플랫폼인 누구(NUGU)가 탑재되었다. 누구는 다른 여타의 음성 AI 플랫폼과\n",
        "마찬가지로 빅데이터와 딥러닝 기반으로 작동하며, 스마트 스피커를 위주로\n",
        "보급되고 있다. 누구는 음악 스트리밍 서비스 멜론과 함께 SK텔레콤의 차제\n",
        "음원 서비스인 플로와 연동해 음악 감상을 지원한다. SK텔레콤은 2018년\n",
        "10월에는 누구 서비스 개발을 위한 오픈 플랫폼 ‘누구 디벨로퍼스’를\n",
        "공개하며, 협력을 통한 개방형 생태계 조성에 나섰다. 국내 통신 기업 KT는\n",
        "2017년 1월 출시한 스마트 스피커 기가지니에 음성 AI 플랫폼을 탑재했다.\n",
        "기가지니는 IPTV 셋톱박스에 스마트 스피커를 결합한 형태로 TV 조작에 음성\n",
        "명령을 사용할 수 있는 것이 특징이다. KT는 2019년 11월에는 클라우드\n",
        "방식의 AI 플랫폼과 소프트웨어 개발 도구(SDK)를 파트너사에게 제공함으로써\n",
        "개방형 플랫폼인 ‘기가지니 인사이드’의 생태계 조성에 나선다는 계획을\n",
        "밝혔다. LG유플러스는 독자적인 플랫폼을 구축하지 않고 네이버와의 제휴를\n",
        "통해 음성 AI 서비스를 제공하고 있다. 유플러스 IPTV 서비스와 네이버의\n",
        "스마트 스피커를 연동해 음성으로 TV와 스마트 스피커, 스마트홈 기기를 제어\n",
        "가능하며 AI 리모컨을 통해 음성 명령을 내릴 수도 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crBR6Dq64DOe",
        "colab_type": "text"
      },
      "source": [
        "## 2-2.4  음성 AI의 기술 구현: 자연어 처리\n",
        "\n",
        "자연어 처리는 앞서 말한 인간의 언어인 자연어를 컴퓨터를 이용해 처리하기 위한 기술 분야이다. 이는 인간의 언어를 이해하는 머신러닝 기술을 적용해 각종 정보처리에 이용함으로써 보다 편리하고 빠르게 정보를 획득할 수 있는 장점이 있다. 자연어 처리는 단순 정보검색이나 질의응답 시스템 뿐만 아니라 기계로 번역하거나 자동 통역을 하고 문서 작성, 요약 분류, 철자 오류를 찾아내 수정하는 등 인가의 언어가 사용되는 많은 영역에서 응용되고 있다.\n",
        " \n",
        "자연어 처리는 최근 빅데이터와 인공지능, 딥러닝의 바람을 타고 관심이 높아지고 있는 기술이다. 대부분의 인공지능 기술처럼 이론적 성능과 기술적인 수준 사이에는 큰 차이가 있기 때문에 차이를 좁히기 위해서는 엄청난 양의 데이터와 이에 기반된 다양한 소트웨어적 노하우가 필요하다. 단순한 정의와 기존 모듈의 정의가 아니기 때문에 상당히 어렵다.\n",
        "\n",
        "이러한 자연어 처리의 핵심 기술은 ①형태소 분석기술 ②구문분석 기술 ③의미분석 기술 ④담화분석 기술 ⑤단어 및 문장 생성기술 이라고 할 수 있다. 가장 기초적인 기술로 형태소 분석이 단어 단위에서 이루어 지고, 그 결과를 토대로 문장 단위, 문서단위의 구문분석, 의미분석, 담화분석이 진행되기 때문에 단어를 단위로 하는 분석결과를 기반으로 하는 문장, 문서 단위의 구문과 의미, 담화분석이 더욱 복잡하며 어려운 기술이라 할 수 있다.\n",
        "\n",
        "인공지능의 연구분야로서의 자연어 처리는 음성을 인식해 형태소를 분석하고, 통사와 의미를 분석하는 데에 있다. 반면 자연어 처리를 위한 인공지능 기술을 사용하는 것은 형태론, 구문론, 의미론, 화용론적 언어지식을 표현할 수 있는 것에 있다. 자연어 처리에 있어서 한국어는 처리가 어려운 언어에 속하는데 같은 동음이의어처럼 중의성이 있는 단어는 머신러닝 기법을 통해 해결할 수 있는데 그러한 기계학습 알고리즘으로는 딥러닝(Deep learning), 결정 나무(Decision tree), 선형분리자, SVN, HMM, Maximum Entropy 등이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4YpxPzK4zzJ",
        "colab_type": "text"
      },
      "source": [
        "## 2-2.5  음성 AI의 기술 전망: 자연어 처리\n",
        "\n",
        "자연어 처리를 쓰는 분야는 텍스트 분석, 기계 번역과 언어 모델, 질의응답 시스템은 물론이거니와 최근의 음성인식, 영상처리 기술과 결합되어 개인비서나 이미지 캡션 생성 기술로까지 발전되고 있는 추세이다. 딥러닝(Deep learning)을 활용하기 전 자연어 처리 기술은 대부분 규칙 기반의 (Rule based) 알고리즘으로 상용화하기 어려웠고 그 성능도 인간과 비교했을 때 월등히 떨어졌다. 하지만 하드웨어와 기계학습(Machine learning) 기술의 급격한 발전으로 자연어 처리기술 역시 이전과 비교하면 뛰어난 성능을 보이고 있으며, 최근에는 GPU와 클라우드 컴퓨팅을 활용한 대량의 빅데이터와 매우 복잡한 모델을 이용해 패턴 학습이 가능한 딥러닝(Deep learning)과 같은 기법을 자연어 처리에 적용하고 있다.\n",
        "\n",
        "자연어 처리 기술은 기계 번역 이외에도 QA 시스템과 감성분석(sentiment analysis), 개인비서와 같이 인간과 컴퓨터의 소통이 필요한 산업 전반에 활용 가능하다. 자연어 처리에 대한 시장 수요도 급등하고 있어 2015년에 약 3000억원 규모로 추정되었던 자연어 처리 기술의 글로벌 시장이 2024년에는 약 2조 3천억원으로 그 규모가 성장할 것으로 예측하고 있다. (시장조사 기관 Tractica 결과 인용) \n",
        "\n",
        "인공지능 연구의 궁극적 목표를 생각해보면 인간과 비슷한 수준까지 인공지능 기술을 끌어올려 다양한 개발을 하는 것인데 이 목표를 위해서는 반드시 자연어 처리에 관한 연구가 필수적으로 이루어 져야 한다. 아직까지도 인간수준의 자연어 처리 능력은 부족해 보이지만 최근 딥러닝(Deep learning) 으로 인해 인공지능 분야에 대한 관심도 높아지고 있으므로 자연어 처리 기술 역시 이에 맞춰 빠르게 발전할 것으로 전망한다.\n",
        "\n",
        "***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okfJs1MLEc5J",
        "colab_type": "text"
      },
      "source": [
        "# 2-3 . 이미지 분야에서의 인공지능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGwUDEqjEnF1",
        "colab_type": "text"
      },
      "source": [
        "## 2-3.1 인공지능으로 분류하는 이미지: 구글 포토 서비스\n",
        "\n",
        "이미지 인식 기술은 이미 우리 생활 가까이에서 많이 사용되고 있다. 스마트폰으로 사진 촬영을 자주 하시는 분이라면 구글 포토 서비스에 사진을 백업해두고 있을 것이다. 고화질 원본 이미지가 아니라면 무제한 저장 용량을 제공하고, 구글 포토는 놀라운 분류와 검색 기능을 가지고 있다. \n",
        "어떤 지역에서 찍은 사진을 찾고 싶거나, 특정 인물을 검색하고 싶다면 구글 포토가 알아서 만들어 놓은 사진첩을 통해 관련 사진을 찾을 수 있다. 심지어 강아지가 등장하는 사진, 우산을 들고 찍은 사진을 찾고 싶다면 검색어로 ‘강아지’, ‘우산’ 등을 입력해보세요! 짜잔~ 여러분이 저장한 사진 중에서 해당 이미지가 포함된 사진을 검색해 결과로 보여준다. 그렇다면 구글 포토는 어떻게 강아진 사진을 분류할 수 있을까? 바로 인공지능의 대표적인 이론인 딥러닝을 통해 컴퓨터가 이미지를 스스로 분류하거나 태깅할 수 있게 하여 가능했다. 이는 다음 장에 자세히 알아보겠다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtj3TNcLE_1N",
        "colab_type": "text"
      },
      "source": [
        "## 2-3.2 이미지 딥러닝 기술: 데이터 기반 이미지 분류\n",
        "\n",
        "이미지 분류는 컴퓨터 비전 분야의 주요 문제이다. 사람은 고양이를 보고 고양이라고 쉽게 분류할 수 있지만, 컴퓨터에게는 매우 어려운 문제이다. 사람은 고양이를 실체가 있는 물체로 인식하는 반면 컴퓨터에게는 0~255 사이의 숫자로 표현되기 때문이다. 이미지 분류의 문제는 이러한 사람과 컴퓨터의 사물을 보는 차이에서 온다.\n",
        "\n",
        " 이러한 문제를 해결하기 위해 제시된 것이 데이터 기반 방법이다. 데이터 기반 방법은 사람이 직접 알고리즘을 만드는 것이 아니라 데이터를 기반으로 모델을 만들어 문제를 해결하고자 하는 방법이다. 결론부터 말하면 이미지 분석에 있어 데이터 기반 방법은 규칙 기반 방법보다 거의 모든 측면에서 효과적이다. 또한 사람이 학습하는 방법과도 비슷하다. \n",
        "  \n",
        " 데이터 기반 방법은 수많은 이미지와 레이블이 있는 데이터셋을 통해 모델을 학습한다. 이 때, 모델을 학습하는 것을 머신 러닝이라고 말한다. 이렇게 학습된 머신러닝 모델은 새로운 이미지를 인풋으로 받아 그 이미지의 레이블을 예측한다. 즉, 이미지를 분류하는 모델을 만드는 방법 중 데이터 기반 방법을 머신러닝이라고 하며, 머신러닝 모델은 데이터셋을 통해 이미지를 학습하는 과정과 새로운 이미지를 예측하는 과정이 있다. 머신러닝 모델의 학습을 위한 데이터셋은 직접 웹 등으로부터 수집할 수 있다. 또한 ImageNet, CIFAR 등 공개된 질 좋은 데이터셋도 있기 때문에 누구나 직접 머신러닝 모델을 구축해볼 수 있다. 예를 들어, CIFAR-10 데이터셋은 10개의 클래스, 50000개의 트레이닝셋, 10000개의 테스트셋으로 구성된다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP_f5tPVF7Xw",
        "colab_type": "text"
      },
      "source": [
        "## 2-3.3 구글포토의 이미지 딥러닝 기술 구현\n",
        "\n",
        "구글의 인공지능은 어떤 원리로 이미지를 '사람처럼' 분석할 수 있는 것일까? 여기에는 고도의 클라우드 컴퓨팅, 머신러닝, 딥러닝 기술이 이용됐다. 가장 먼저 한 작업은 클라우드 컴퓨팅 속 CPU 묶음과 머신러닝을 활용해 인공지능을 교육한 것이다. 먼저 사람이 직접 주석을 단 이미지를 입력해 인공지능에게 바른 방향을 제시했다. 그 다음 수 많은 이미지를 인공지능에 입력해 인공지능이 주석을 달도록 했다. 이렇게 나온 이미지 주석을 사람이 평가해서 무엇이 맞고 무엇이 틀린지 인공지능에게 알려줬다.\n",
        "\n",
        "그 다음 단계는 자습이다. 사람이 입력한 데이터를 바탕으로 인공지능 스스로 이미지를 분석하고 주석을 달은 후 스스로 평가하기 시작했다. 이 과정을 수 없이 반복해서 이미지 분석 기능을 스스로 향상시켰다.여기에 클라우드 컴퓨팅 속 GPU 묶음과 딥러닝을 활용한 이미지 인식 기능을 추가했다. 사람은 이미지를 보고 단숨에 그것이 무엇인지 알 수 있지만, 인공지능에게 이미지란 단지 특정 색상으로 이뤄진 점(픽셀)의 모임일 뿐이다. 이를 수 많은 신경망 계층을 거쳐 사람처럼 인식할 수 있도록 만드는 기술이 딥러닝이다.\n",
        "\n",
        "이렇게 이미지를 인식하고 분석할 수 있게 구글은 내부에서 만든 인공지능이 바로 '인셉션' 이미지 엔진이다. 사진을 인식해서 자동으로 정렬해주는 구글의 서비스 '구글 포토'에도 바로 이 인셉션 이미지 엔진이 적용되어 있다.\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26uiIYt7dwbP",
        "colab_type": "text"
      },
      "source": [
        "# 2-4 . 자율주행 분야에서의 인공지능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWRAcGd3sM",
        "colab_type": "text"
      },
      "source": [
        "## 2-4.1  자율주행 개념\n",
        "\n",
        " 최근 몇년간 많은 언론에서 자율주행차를 다루었다. 막연히 자율주행차를 혼자서 움직이는 자동차라 생각할 뿐, 자율주행차의 개념에 대해 생각해보지 않았다. 본 글에서 자율주행차의 개념을 정의해보고자 한다. \n",
        "\n",
        " 국제자동차기술자협회에 따르면 자율주행차는 여섯 단계로 나뉜다. 자율주행 기능이 없는 일반 자동차에 해당하는 0단계부터 모든 환경 하에서 운전자의 개입이 필요하지 않은 완전 자동화 상태인 5단계로 이루어져 있다. \n",
        "\n",
        " 그렇다면 현재 자동차 브랜드들이 추진하고 자율주행차는 어느 단계에 위치하고 있을까? 현재 글로벌 자동차 기업뿐만 아니라 구글, 애플 등 글로벌 IT 기업들이 기술개발에 참여하고 있다. 이미 3, 4단계 수준의 기술을 보유하고 있지만 해당 당국과 각종 업계들과의 조율로 인해 5단계까지 이른 사례는 많지 않다. 즉 기술 수준은 자동차 내 인공수준에 의해 제한적인 자율주행, 혹은 더 나아가 완전한 자율주행을 실현할 수 있지만 자율주행이 가지는 문제점과 정책적 문제란 벽이 남아있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwrV_PReeT5N",
        "colab_type": "text"
      },
      "source": [
        "## 2-4.2  자율주행차 주요 기술: 인공지능의 대표적인 이론, 딥러닝\n",
        "\n",
        " 운전을 할 때 숙련된 운전자여도 가슴이 덜컥 내려앉을 때가 바로 예상치 못한 물체와 마주했을 것이다. 그것이 차량일 수도 있고 보행자일 수도 있고, 혹은 바람에 날린 봉투일 수도 있다. 그러나 운전자는 그 물체가 무엇이냐에 따라 순간적인 의사결정을 통해 운전방식을 바꿔야 한다. 즉 물체를 분류하고, 그 물체에 따른 적절한 행동이 이어져야 하는 것이다. \n",
        "\n",
        " 자율주행차의 핵심적인 기술 역시 위와 같은 사람의 본능적인 물체 분류과정을 자동차가 할 수 있도록 하는 것이다. 바로 인간이 경험을 거치며 스스로 학습한 과정을 기계가 모방하는 '머신러닝'이다. 이 중 소개하고자 하는 이론은 바로 인간이 물제를 발견하고 작동하는 뇌 신경망을 모방하여, 신경 네트워크를 형성하는 '딥러닝'이다. \n",
        "\n",
        " 딥러닝을 활용하여 인공지능으로 구현하려면 사람이 태어나면서 부터 물체를 하나씩 인식한 것처럼 컴퓨터 역시 데이터를 반복적으로 입력하는 과정을 통해 컴퓨터가 필요한 기능을 스스로 학습하도록 하는 것이다. 따라서 자율주행차를 위한 인공지능 구현에서 핵심은 프로그래밍과 같은 전문 지식보다는 컴퓨터를 충분히 학습시킬 수 있는 데이터이다. 오늘날 딥러닝이 신기술로 주목받을 수 있었던 것도 바로 빅데이터 기술의 발전으로 학습에 사용할 수 있는 데이터의 양과 종류가 엄청 늘어났고, 딥러닝의 방대한 자료를 처리할 수 있는 컴퓨팅 플랫폼도 날로 발전하고 있다. 즉, 딥러닝이란 사물이나 데이터 인식에 쓰이는 대표적인 머신러닝 기술 중 하나로 인간이 경험을 통해 스스로 학습하듯 딥러닝은 컴퓨터가 수많은 데이터를 반복적으로 접한 다음, 정보를 스스로 인지할 수 있게 하는 방식이다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3hMDQoqengK",
        "colab_type": "text"
      },
      "source": [
        "## 2-4.3  자율주행차 인공지능 기술 구현 : 딥러닝\n",
        "\n",
        " 앞서 자율주행차의 주요 기술인 딥러닝에 대해 소개했다면, 이번 장은 딥러닝이 자율주행차에 어떤 기능을 하는기 구체적으로 기술 실현 프로세스를 소개하고자 한다. \n",
        "\n",
        " 자율주행 자동차는 앞서 다루었 듯이 스스로 주행하려면 인지, 판단, 제어 등 세가지 기능이 반드시 필요하다. 인지 기능은 카메라∙레이더∙라이다( 등 차체 내 센서 정보를 처리해 주변 환경 정보를 알아차리는 것이고, 판단 기능은 인지된 정보를 이용해 향후 벌어질 일을 예측한 후 가장 안전하고 빠른 차량 궤적을 생성하는 것이다. 마지막으로 제어 기능은 최종적으로 생성된 차량 궤적을 부드럽고 정확하게 따라갈 수 있도록 운전대∙액셀러레이터∙브레이크를 조작하는 것이다. 자율주행 자동차에 필수적인 인지기능, 판단기능, 제어기능에서 딥러닝의 역할을 다루어보겠다. \n",
        "\n",
        "\n",
        "\n",
        "* 1) 인지기능\n",
        "\n",
        "  카메라를 통해 입력된 이미지에 딥러닝을 적용하면 자율주행 시스템에 필요한 정적 환경 정보인 차선∙운전가능도로∙교통표지판∙교통신호 등과 동적 환경 요소인 차량∙보행자∙이륜차 등을 전부 검출하고 분류할 수 있다.\n",
        "\n",
        "\n",
        "* 2) 판단기능\n",
        "   \n",
        "   다양한 운전 방식과 관련 센서 정보를 데이터로 입력한 후 이를 딥러닝 알고리즘으로 학습한다면 정확한 수학 모델 없이 데이터만으로도 다른 운전자의 운행을 예측할 수 있는 인공지능 구현이 가능하다. 미래의 움직임을 판단하고 결정하려면 다른 운전자의 움직임을 예측해야 한다. 하지만 다양한 운전 방식을 파악하고 이를 (정답이 딱 떨어지는) 수학 모델로 정의하긴 쉽지 않다. 다른 차량 운전자가 어떻게 운전할지 논리적으로 예측하는 건 불가능하기 때문이다. 이처럼 행동 방식을 논리적으로 파악하기 어려울 때 딥러닝은 매력적 솔루션이 된다. \n",
        "\n",
        "\n",
        "* 3) 제어 기능\n",
        "\n",
        "  고도의 안정성이 요구되는 차량 제어 기능을 구현하려면 검증된 기존 기술을 사용하는 게 일반적이다. 하지만 탑승자의 승차감을 튜닝하기 위한 제어 기능엔 딥러닝을 적용할 여지가 있다. 승차감은 개개인이 느끼는 감성적 요소인 만큼 ‘공학적 기준’을 만들어 적용하기엔 한계가 있다. 따라서 이 경우, 딥러닝 기술을 활용해 개개인의 운전 방식을 데이터화하면 인간 감성을 고려한 차량 제어가 가능해진다. 다시 말해 단순 자율주행 기능뿐 아니라 탑승자의 안색∙음성∙상태 등을 인식, 개별 탑승자에게 ‘맞춤형 편의 기술’을 제공하는 서비스에도 딥러닝이 적용될 수 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwuX20A-D1pS",
        "colab_type": "text"
      },
      "source": [
        "## 2-4.4 자율주행 대표 서비스: 앱티브의 라이드쉐어링\n",
        "\n",
        "인지시스템, 소프트웨어 알고리즘, 컴퓨팅 플랫폼,  등 업계 최고의 모빌리티 솔루션인 앱티브는 2018 CES에서 악천후 조건에도 불구하고 자율주행 시승행사를 성공적으로 시연했다. 이어 앱티브는 라이드쉐어링 업체 리프트(와 함께 라스베이거스에서 자율주행 로보택시 서비스를 세계최초로 시작했으며 이를 통해 지속적으로 노하우를 쌓아오고 있다.\n",
        "\n",
        "2018 CES 이후 첫 선을 보인 앱티브의 자율주행 로보택시 서비스는 최초에 라스베이거스 내 20개 내외의 목적지 사이만 제한적으로 오갈수 있었으나 이를 지속적으로 개발해온 끝에 지금은 호텔, 식당, 카지노 등 약 3,400여곳의 장소를 목적지로 설정할 수 있다. 또한 서비스 초기 단 1건의 경미한 사고 외에는 무사고 주행을 이어오고 있고 이용자들의 평점도 5점 만점에 4.95점을 기록중인만큼 높은 만족도를 자랑한다. 앱티브는 약 2년간 로보택시 서비스를 운영하며 95,000회 이상의 운행을 기록했다.\n",
        "\n",
        "실제 앱티브의 로보택시 서비스는 다음과 같이 이루어진다.\n",
        "리프트 앱을 설치하고 라스베이거스에서 처음 실행하면 자율주행 이용 동의에 관한 팝업 알림이 뜬다. 이에 동의하면 차량 호출 옵션에 SELF-DRIVING이 추가되고 로보택시 서비스를 이용할 수 있게 된다. 요금은 실제 운전자가 서비스하는 일반적인 이코노미 옵션과 차이가 없다. 앱티브 로보택시 서비스는 리프트 앱에서 정한 거리 당 요금을 그대로 따르고 있기 때문이다.\n",
        " 앞 좌석에 자율주행 운행 불가지역에서의 운전 및 돌발 상황 대비를 위한 운전자와, 자율주행 차량의 기술 설명을 위한 직원이 조수석에 동행한다. \n",
        "\n",
        "앱티브의 자유주행 서비스는 설정한 경로에 따라 차선 변경이 필요하면 방향지시등과 함께 차선 변경을 하고, 신호등에 적색등이 켜졌을 때는 앞 차량이 없어도 스스로 정지선에 맞추어 정차한다. 앱티브 자율주행 차량에도 카메라의 색상과 위치를 판단하는 센서를 장착하여 신호등의 상태를 전송하고 있어 이를 받아 현재 도로의 신호를 판단한다. \n",
        "\n",
        "한가지 자율주행에 중요한 요소는 지도인데 앱티브는 자체 제작한 지도를 사용하고 이를 지속적으로 업데이트 해오고 있다. 우리가 흔히 사용하는 구글맵이나 애플맵 등은 약 30cm 내외의 오차를 보이지만 앱티브가 적용한 자율주행 전용 지도는 수 cm 단위 이내의 오차를 보일 정도로 정교하게 구현되어 있다.\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIorbU_PFOHR",
        "colab_type": "text"
      },
      "source": [
        "# 결론\n",
        "\n",
        "앞서 살펴본 바와 같이 인공지능 기술은 이미 여러 서비스와 제품을 통해 우리 생활 깊숙이 다가와 있으며, 앞으로는 데이터에 기반한 거의 모든 산업이 인공지능 기술로 인해 자동화되고 최적화될 것이다. 또한 전통적인 산업의 혁신뿐 아니라, 고도의 지적 능력과 현장 경험이 필요한 전문가의 영역도 인공지능이 대신하거나 전문가와 함께 협업하는 모습이 낯설지 않은 상황에 와 있다. 하지만 이러한 급속한 확산이 인공지능의 기술적 완성을 의미하는 것은 아니며, 오히려 기존에 인간이 수행하는 대부분의 지적 행위들이 대량의 데이터와 충분한 연산량, 그리고 효율적으로 훈련이 가능한 기계학습 모델을 이용해 구현이 가능한 것이었음을 확인해주었다고 보는 것이 적합하다. 해당 분야 전문가들과 인공지능의 조화로운 역할 분담과 협업을 통해, 이러한 협업을 효율적으로 가능하도록 하는 사용자 환경을 잘 구축하는 것이 인공지능 제품이나 서비스의 핵심 경쟁력이 될 것이라 생각한다. \n",
        "\n",
        "***"
      ]
    }
  ]
}
